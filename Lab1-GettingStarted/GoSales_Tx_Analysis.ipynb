{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lab1 (continued) - Working with Jupyter Notebooks in IBM Watson Studio\n",
    "In this notebook, we will conduct some early exploratory analysis on the `GoSales_Tx.csv` data file.\n",
    "\n",
    "Tips:\n",
    "* Code cells are identifiable by their `In [ ]:` prefix in the margin\n",
    "* To execute the cells in the notebook, select the cell and click the **Run** button, or hit **Ctrl-Enter**.\n",
    "* Cells which have not been executed before will have empty brackets, while executed cells will have a sequence number within, e.g. `In [13]`\n",
    "* Cell execution result displays below the cell\n",
    "* To clear all exection statuses and outputs, use the `Cell/All Output/Clear` menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Getting started:\n",
    "* Select the code cell below, and **delete all its content**\n",
    "* Open the data panel on the right using the    \n",
    "`10`   \n",
    "`01` button icon  (top right)\n",
    "* From the data panel on the right use context menu on `GoSales_Tx.csv` file to _Insert to code/Insert pandas DataFrame_\n",
    "\n",
    "The python source code to create a `df_data_1` panda DataFrame that accesses the `GoSales_Tx.csv` file is generated.\n",
    ">NOTE: If the name is different, change the variable name back to `df_data_1`\n",
    "\n",
    "Then execute the cell (Ctrl-Enter or run button), upon completion, a subset of the data will be shown below the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import types\n",
    "# import pandas as pd\n",
    "# from botocore.client import Config\n",
    "# import ibm_boto3\n",
    "\n",
    "# def __iter__(self): return 0\n",
    "\n",
    "# # @hidden_cell\n",
    "# # The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# # You might want to remove those credentials before you share your notebook.\n",
    "# client_70ab70feb7fb4d8f9a47a408afd9f30f = ibm_boto3.client(service_name='s3',\n",
    "#     ibm_api_key_id='ZATI1oq_TlsWqN-oEz3Wo1IPXWwOkCx0PXV3gj0d5eui',\n",
    "#     ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n",
    "#     config=Config(signature_version='oauth'),\n",
    "#     endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "# body = client_70ab70feb7fb4d8f9a47a408afd9f30f.get_object(Bucket='watstudworkshop-donotdelete-pr-basx79wonvxlys',Key='GoSales_Tx.csv')['Body']\n",
    "# # add missing __iter__ method, so pandas accepts body as file-like object\n",
    "# if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "# df_data_1 = pd.read_csv(body)\n",
    "# df_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the dataframe should be loaded and the 5 first rows displayed.  \n",
    "The following cell checks that no mistake has been made in the variable naming as `df_data_1`, and creates a convenience shortcut variable `df` for the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_data_2' in globals().keys():\n",
    "    df_data_1=df_data_2\n",
    "if not 'df_data_1' in globals().keys():\n",
    "    print(\"***************\\nERROR: df_data_1 variable is not defined, please check the cell above\\n***************\")\n",
    "else:\n",
    "    # Created a convenience shortcut variable\n",
    "    df=df_data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract some facts about the dataset\n",
    "\n",
    "In the following section, we will start using `Pandas` functions to query information about the data represented in the CSV file which was just loaded in a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding out about data types\n",
    "The first thing we will want to know besides the column titles, is the data types of the columns.   \n",
    "For this we use the `DataFrame`'s `dtypes` attribute. The data types have been inferred when loading the CSV file, in this case we can see that:\n",
    "* `IS_TENT` has been identified as a boolean\n",
    "* `AGE` has been inferred as an integer\n",
    "* `GENDER`, `MARITAL_STATUS`, `PROFESSION` are strings which match the generic `object` type.\n",
    "Note that the types themselves are instances of `numpy` data types and are returned in a `Series` object indexed by column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting full rows\n",
    "* We'll use the DataFramce `count()` method to compute non-empty rows for each column in the next code cell\n",
    "\n",
    "In this dataset we should find 60252 data rows for each of the columns, which means that the table has no hollows cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gettings base statistics\n",
    "* Use `describe()` to get statistics on fields:\n",
    "    * The numeric `AGE` confirms the average age is about 34 yo.\n",
    "    * There are 9 unique `PROFESSION` of which the top is 'Other', and 3 `MARITAL_STATUS` of which the top is 'Married'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate frequency of buying behavior\n",
    "* Now we would want to know the proportion of positive buying decisions vs total number of records, so we count the number of each values (here, just boolean True/False) of the **IS_TENT** column:\n",
    "\n",
    ">NOTE: in terms of notation, a `DataFrame` column can be accessed through the `df['colName']` notation, or through the `df.colName` notation, which is available only when the column name does not conflict with python variable naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.IS_TENT.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a roughly one-to-ten ratio of buy vs non-buy\n",
    "\n",
    "#### Get statistics on the 3 string columns\n",
    "Similarly, we count the `GENDER`, `MARITAL_STATUS` and `PROFESSION` values.   \n",
    "You will notice some variations on the code syntax here, using the array indexing notation for `GENDER`, and using the `to_frame()` for `MARITAL_STATUS` to convert the returned `Series` to a `DataFrame` which yields a prettier display in Jupyter notebook output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MARITAL_STATUS.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PROFESSION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute additional statistics\n",
    "* To get the output expressed as percentages, we define a function, implemented as a lambda and assigned to the `pf` variable\n",
    "* The pandas `map()` will apply the function to each cell of a column, we do that for PROFESSION, MARITAL_STATUS, GENDER, IS_TENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf=lambda x: '{0: >2.0f}%'.format(100*x/df.PROFESSION.count())\n",
    "df.PROFESSION.value_counts().map(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MARITAL_STATUS.value_counts().map(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.GENDER.value_counts().map(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.IS_TENT.value_counts().map(pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This refines for example the one-to-nine ratio of buy vs non-buy\n",
    "\n",
    "* Now, we would like to understand which factor drives the buying behavior.   \n",
    "* Without going into Machine Learning yet, we can analyse the correlation between the IS_TENT flag and each one of the other features or variables.\n",
    "* For this we use the `crosstab()` function which ventilates values of one column according to another one\n",
    "\n",
    "Features with less discrete values will be easier to apprehend, let's start with Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tent_gender=pd.crosstab(df.IS_TENT,[df.GENDER])\n",
    "x_tent_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that Male customers tend to buy a tent 2 to 3 times more often than Female ones.\n",
    "\n",
    "* Similarly we can run the same on `PROFESSION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tent_prof=pd.crosstab(df.IS_TENT,[df.PROFESSION])\n",
    "x_tent_prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives an indication that Retired and Executives proportionally buy much less tents than the average.  \n",
    "Other than that it is not very conclusive since a large subset has no specified Profession.\n",
    "\n",
    "* Let's try the same for `AGE` correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_tent_age=pd.crosstab(df.IS_TENT,[df.AGE])\n",
    "# Show transposed, with Age as rows, and False, True columns as values\n",
    "x_tent_age.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are a bit less obvious to grasp without a graphical representation.\n",
    "\n",
    "* As a glimpse into the next lab, we can use matplotlib to quickly display the result, here we will show the buy ratio vs number of visitors per age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.bar(x_tent_age.T.index,x_tent_age.T[True]/(x_tent_age.T[False]+x_tent_age.T[True]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Conclusion: We see in the plot above that visitors in their mid-20s are more likely to purchase a Tent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
